{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create and train ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import base\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dill\n",
    "from datetime import datetime,timedelta\n",
    "from sklearn.linear_model import LinearRegression, SGDClassifier, Ridge, SGDRegressor\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from pandas.plotting import lag_plot\n",
    "#from pandas import datetime\n",
    "from statsmodels.tsa.arima_model import ARIMA\n",
    "import os\n",
    "from ediblepickle import checkpoint\n",
    "import updates\n",
    "from collections import Counter, defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create news file with sentiment index\n",
    "\n",
    "We only have sentiment labels for a portion of the news, so we use those labels to create train data, so the rest of the news is labeled using the trained model.\n",
    "\n",
    "Only done once, do not re-run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment_dict= dill.load(open('data/sentiment_dict.pkd', 'rb'))\n",
    "tickers = dill.load(open('data/tickers.pkd', 'rb'))\n",
    "\n",
    "today=datetime(datetime.now().year,datetime.now().month,datetime.now().day)\n",
    "last_news_update=dill.load(open('data/last_news_update.pkd', 'rb'))\n",
    "if last_news_update!=today:\n",
    "    !rm data/BenzNewscache/*\n",
    "    updates.update_all_news()\n",
    "    last_news_update=today\n",
    "    dill.dump(last_news_update, open('data/last_news_update.pkd', 'wb'))\n",
    "    \n",
    "all_ticker_news = dill.load(open('data/all_ticker_news.pkd', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">A</th>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>71.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23</th>\n",
       "      <td>71.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>71.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>71.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>71.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"5\" valign=\"top\">ZTS</th>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>77.24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>77.36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>80.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>80.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-21</th>\n",
       "      <td>80.70</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6685 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   Sentiment\n",
       "Ticker Date                 \n",
       "A      2020-10-21      71.68\n",
       "       2020-10-23      71.68\n",
       "       2020-10-26      71.68\n",
       "       2020-10-27      71.68\n",
       "       2020-10-28      71.73\n",
       "...                      ...\n",
       "ZTS    2020-11-05      77.24\n",
       "       2020-11-06      77.36\n",
       "       2020-11-09      80.70\n",
       "       2020-11-10      80.70\n",
       "       2020-11-21      80.70\n",
       "\n",
       "[6685 rows x 1 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dates=[]\n",
    "sentiments=[]\n",
    "ticks=[]\n",
    "for date,ticker_dict in sentiment_dict.items():\n",
    "    for ticker,value in ticker_dict.items():\n",
    "        if value>0:\n",
    "            dates.append(date)\n",
    "            sentiments.append(value)\n",
    "            ticks.append(ticker)\n",
    "df_sentiment=pd.DataFrame()\n",
    "df_sentiment['Ticker']=ticks\n",
    "df_sentiment['Date']=dates\n",
    "df_sentiment['Sentiment']=sentiments\n",
    "df_sentiment=df_sentiment.set_index(['Ticker','Date']).sort_index()\n",
    "df_sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-21</th>\n",
       "      <td>78.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-23</th>\n",
       "      <td>77.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>77.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>79.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-28</th>\n",
       "      <td>77.71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>78.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>78.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>78.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>79.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>80.87</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>80.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>78.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>77.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-21</th>\n",
       "      <td>79.23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Sentiment\n",
       "Date                 \n",
       "2020-10-21      78.35\n",
       "2020-10-23      77.48\n",
       "2020-10-26      77.76\n",
       "2020-10-27      79.89\n",
       "2020-10-28      77.71\n",
       "2020-10-29      78.03\n",
       "2020-10-30      78.75\n",
       "2020-11-03      78.89\n",
       "2020-11-04      79.83\n",
       "2020-11-05      80.87\n",
       "2020-11-06      80.33\n",
       "2020-11-09      78.73\n",
       "2020-11-10      77.95\n",
       "2020-11-21      79.23"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sentiment.loc['MSFT']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_word_file(word_type):\n",
    "    l=[]\n",
    "    filename=word_type+'_words.txt'\n",
    "    with open(filename,'r') as wf:\n",
    "        for line in wf:\n",
    "            if line[0] != ';' and line[0] != '\\n':\n",
    "                l.append(line.strip())\n",
    "    return l\n",
    "\n",
    "l_pos_words=read_word_file('positive')\n",
    "l_neg_words=read_word_file('negative')\n",
    "\n",
    "def pos_sentiment(txt):\n",
    "    word_list=[x.lower() for x in txt.split()]\n",
    "    return len([x for x in word_list if x in l_pos_words])\n",
    "\n",
    "def neg_sentiment(txt):\n",
    "    word_list=[x.lower() for x in txt.split()]\n",
    "    return -len([x for x in word_list if x in l_neg_words])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_traindata():\n",
    "    train_data=pd.DataFrame(columns=['Ticker','Date','NewsText','PosSentiment'\n",
    "                                   ,'NegSentiment','SentimentIndex','Sentiment','SentimentClass'])\n",
    "    for ticker,date in df_sentiment.index:\n",
    "        data=pd.DataFrame()\n",
    "        news=[]\n",
    "        dates=[]\n",
    "        sentiments=[]\n",
    "        if all_ticker_news[ticker]==None:\n",
    "            continue\n",
    "        elif all_ticker_news[ticker].get(date,0)==0:\n",
    "            continue\n",
    "        for item in all_ticker_news[ticker][date]:\n",
    "            news.append(item)\n",
    "            dates.append(date)\n",
    "            sentiments.append(df_sentiment.loc[ticker].loc[date][0])\n",
    "        data['Ticker']=[ticker]*len(news)\n",
    "        data['Date']=dates\n",
    "        data['NewsText']=news   \n",
    "        data['PosSentiment']=data['NewsText'].apply(pos_sentiment)\n",
    "        data['NegSentiment']=data['NewsText'].apply(neg_sentiment)\n",
    "        upper_bound=max(data['PosSentiment'].max(),data['NegSentiment'].max())\n",
    "        data['SentimentIndex']=50*(data['PosSentiment']-data['NegSentiment'])/upper_bound+50\n",
    "        data['SentimentIndex']=data['SentimentIndex'].fillna(50)\n",
    "        data['Sentiment']=sentiments\n",
    "        data['SentimentClass']=['Positive' if x>70 else 'Negative' if x<30 else 'Neutral' for x in sentiments]\n",
    "        train_data=train_data.append(data)\n",
    "    train_data=train_data.set_index(['Ticker','Date']).sort_index()\n",
    "    return train_data\n",
    "all_data=prep_traindata()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>PosSentiment</th>\n",
       "      <th>NegSentiment</th>\n",
       "      <th>SentimentIndex</th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2020-10-26</th>\n",
       "      <td>FAANGs In Focus: Amazon, Facebook, Apple, Alph...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.28</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>The Daily Biotech Pulse: Catabasis Halts Duche...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.42</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>Recap: Merck &amp; Co Q3 Earnings</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.42</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>A Peek Into The Markets: US Stock Futures Edge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.42</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>7 Stocks To Watch For October 27, 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.42</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-27</th>\n",
       "      <td>Earnings Scheduled For October 27, 2020</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>73.42</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-29</th>\n",
       "      <td>The Daily Biotech Pulse: Novartis Acquires Gen...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.23</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-30</th>\n",
       "      <td>Attention Biotech Investors: Mark Your Calenda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.17</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-03</th>\n",
       "      <td>Attention Biotech Investors: Mark Your Calenda...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>74.17</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>Rich Saperstein And Joe Terranova Share Their ...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>74.60</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>The Daily Biotech Pulse: Bluebird Bio Plunges ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>72.25</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>The Daily Biotech Pulse: Lilly's COVID-19 Anti...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>inf</td>\n",
       "      <td>72.57</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     NewsText PosSentiment  \\\n",
       "Date                                                                         \n",
       "2020-10-26  FAANGs In Focus: Amazon, Facebook, Apple, Alph...            0   \n",
       "2020-10-27  The Daily Biotech Pulse: Catabasis Halts Duche...            0   \n",
       "2020-10-27                      Recap: Merck & Co Q3 Earnings            0   \n",
       "2020-10-27  A Peek Into The Markets: US Stock Futures Edge...            0   \n",
       "2020-10-27             7 Stocks To Watch For October 27, 2020            0   \n",
       "2020-10-27            Earnings Scheduled For October 27, 2020            0   \n",
       "2020-10-29  The Daily Biotech Pulse: Novartis Acquires Gen...            0   \n",
       "2020-10-30  Attention Biotech Investors: Mark Your Calenda...            0   \n",
       "2020-11-03  Attention Biotech Investors: Mark Your Calenda...            0   \n",
       "2020-11-04  Rich Saperstein And Joe Terranova Share Their ...            1   \n",
       "2020-11-05  The Daily Biotech Pulse: Bluebird Bio Plunges ...            0   \n",
       "2020-11-10  The Daily Biotech Pulse: Lilly's COVID-19 Anti...            0   \n",
       "\n",
       "           NegSentiment  SentimentIndex  Sentiment SentimentClass  \n",
       "Date                                                               \n",
       "2020-10-26            0            50.0      74.28       Positive  \n",
       "2020-10-27            0            50.0      73.42       Positive  \n",
       "2020-10-27            0            50.0      73.42       Positive  \n",
       "2020-10-27            0            50.0      73.42       Positive  \n",
       "2020-10-27            0            50.0      73.42       Positive  \n",
       "2020-10-27            0            50.0      73.42       Positive  \n",
       "2020-10-29            0            50.0      74.23       Positive  \n",
       "2020-10-30            0            50.0      74.17       Positive  \n",
       "2020-11-03            0            50.0      74.17       Positive  \n",
       "2020-11-04            0           100.0      74.60       Positive  \n",
       "2020-11-05            0            50.0      72.25       Positive  \n",
       "2020-11-10           -1             inf      72.57       Positive  "
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data.loc['MRK']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>PosSentiment</th>\n",
       "      <th>NegSentiment</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ticker</th>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">A</th>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Friday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Monday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AAP</th>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>Recap: Advance Auto Parts Q3 Earnings</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">ZION</th>\n",
       "      <th>2020-11-09</th>\n",
       "      <td>74 Stocks Moving In Monday's Mid-Day Session</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-10</th>\n",
       "      <td>100 Biggest Movers From Yesterday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"3\" valign=\"top\">ZTS</th>\n",
       "      <th>2020-11-04</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Wednesday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>Stocks That Hit 52-Week Highs On Thursday</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-06</th>\n",
       "      <td>The Daily Biotech Pulse: Novartis Drug Flunks ...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1802 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                            NewsText  \\\n",
       "Ticker Date                                                            \n",
       "A      2020-11-04         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "       2020-11-05          Stocks That Hit 52-Week Highs On Thursday   \n",
       "       2020-11-06            Stocks That Hit 52-Week Highs On Friday   \n",
       "       2020-11-09            Stocks That Hit 52-Week Highs On Monday   \n",
       "AAP    2020-11-10              Recap: Advance Auto Parts Q3 Earnings   \n",
       "...                                                              ...   \n",
       "ZION   2020-11-09       74 Stocks Moving In Monday's Mid-Day Session   \n",
       "       2020-11-10                  100 Biggest Movers From Yesterday   \n",
       "ZTS    2020-11-04         Stocks That Hit 52-Week Highs On Wednesday   \n",
       "       2020-11-05          Stocks That Hit 52-Week Highs On Thursday   \n",
       "       2020-11-06  The Daily Biotech Pulse: Novartis Drug Flunks ...   \n",
       "\n",
       "                  PosSentiment NegSentiment  \n",
       "Ticker Date                                  \n",
       "A      2020-11-04            0            0  \n",
       "       2020-11-05            0            0  \n",
       "       2020-11-06            0            0  \n",
       "       2020-11-09            0            0  \n",
       "AAP    2020-11-10            0            0  \n",
       "...                        ...          ...  \n",
       "ZION   2020-11-09            0            0  \n",
       "       2020-11-10            0            0  \n",
       "ZTS    2020-11-04            0            0  \n",
       "       2020-11-05            0            0  \n",
       "       2020-11-06            0           -1  \n",
       "\n",
       "[1802 rows x 3 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_data[['NewsText','PosSentiment','NegSentiment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN 0.6208425720620843\n",
      "SGD 0.6430155210643016\n",
      "RFC 0.6252771618625277\n"
     ]
    }
   ],
   "source": [
    "class AddTfIdfVect(base.BaseEstimator, base.TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.tfidf=TfidfVectorizer(stop_words=STOP_WORDS.union({'ll', 've'}))\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        self.tfidf.fit(X['NewsText'])\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        X_transformed=pd.DataFrame(self.tfidf.transform(X['NewsText']).todense())\n",
    "        X_transformed['PosSentiment']=X['PosSentiment'].values\n",
    "        X_transformed['NegSentiment']=X['NegSentiment'].values\n",
    "        return X_transformed\n",
    "    \n",
    "X=all_data[['NewsText','PosSentiment','NegSentiment']]\n",
    "y=all_data['SentimentClass'].values\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n",
    "classifiers={'KNN':KNeighborsClassifier(n_neighbors=7),\n",
    "            'SGD':SGDClassifier(max_iter=1000),\n",
    "            'RFC':RandomForestClassifier(n_estimators=100)}\n",
    "for name,classifier in classifiers.items():\n",
    "    pipe = Pipeline([('vectorizer', AddTfIdfVect()),\n",
    "                    ('classifier', classifier)])\n",
    "    pipe.fit(X_train,y_train)\n",
    "    print(name,pipe.score(X_test,y_test) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('vectorizer', AddTfIdfVect()),\n",
       "                ('classifier',\n",
       "                 SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "                               early_stopping=False, epsilon=0.1, eta0=0.0,\n",
       "                               fit_intercept=True, l1_ratio=0.15,\n",
       "                               learning_rate='optimal', loss='hinge',\n",
       "                               max_iter=1000, n_iter_no_change=5, n_jobs=None,\n",
       "                               penalty='l2', power_t=0.5, random_state=None,\n",
       "                               shuffle=True, tol=0.001, validation_fraction=0.1,\n",
       "                               verbose=0, warm_start=False))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sgdpipe1 = Pipeline([('vectorizer', AddTfIdfVect()),\n",
    "                ('classifier', SGDClassifier(max_iter=1000))])\n",
    "\n",
    "sgdpipe1.fit(all_data[['NewsText','PosSentiment','NegSentiment']]\n",
    "             ,all_data['SentimentClass'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SGDClassifier(alpha=0.0001, average=False, class_weight=None,\n",
       "              early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True,\n",
       "              l1_ratio=0.15, learning_rate='optimal', loss='hinge',\n",
       "              max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty='l2',\n",
       "              power_t=0.5, random_state=None, shuffle=True, tol=0.001,\n",
       "              validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer=AddTfIdfVect()\n",
    "vectorizer.fit_transform(all_data[['NewsText','PosSentiment','NegSentiment']])\n",
    "news_classifier=SGDClassifier(max_iter=1000)\n",
    "news_classifier.fit(vectorizer.fit_transform(all_data[['NewsText','PosSentiment','NegSentiment']])\n",
    "                    ,all_data['SentimentClass'].values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(news_classifier, open('predict_data/news_classifier.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_old_news():\n",
    "    old_news=pd.DataFrame(columns=['Ticker','Date','NewsText','PosSentiment','NegSentiment'])\n",
    "    for ticker,newsdict in all_ticker_news.items():\n",
    "        data=pd.DataFrame()\n",
    "        news=[]\n",
    "        dates=[]\n",
    "        if newsdict==None:\n",
    "            continue\n",
    "        for date,newslist in newsdict.items():\n",
    "            if date<datetime.datetime(2020,10,21):\n",
    "                for item in newslist:\n",
    "                    news.append(item)\n",
    "                    dates.append(date)\n",
    "        data['Ticker']=[ticker]*len(news)\n",
    "        data['Date']=dates\n",
    "        data['NewsText']=news\n",
    "        data['PosSentiment']=data['NewsText'].apply(pos_sentiment)\n",
    "        data['NegSentiment']=data['NewsText'].apply(neg_sentiment)\n",
    "        old_news=old_news.append(data)\n",
    "    return old_news"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=prep_old_news()\n",
    "news['SentimentClass']=sgdpipe1.predict(news[['NewsText','PosSentiment','NegSentiment']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "news=news.set_index(['Ticker','Date']).sort_index()\n",
    "news=news.append(all_data[['NewsText','PosSentiment','NegSentiment','SentimentClass']])\n",
    "news['SentimentIndex']=news['SentimentClass'].apply(lambda x: 1 if x=='Positive' else -1 if x=='Negative' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(news, open('data/news.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "54361"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY 54419\n",
      "ABT 54421\n",
      "ABMD 54422\n",
      "ATVI 54423\n",
      "AAP 54425\n",
      "AFL 54426\n",
      "A 54427\n",
      "APD 54436\n",
      "ALK 54442\n",
      "ALB 54444\n",
      "ALXN 54445\n",
      "ALGN 54452\n",
      "ALLE 54454\n",
      "LNT 54455\n",
      "GOOGL 54531\n",
      "GOOG 54555\n",
      "AMZN 54594\n",
      "AMCR 54596\n",
      "AEP 54599\n",
      "AXP 54602\n",
      "AIG 54603\n",
      "AMP 54604\n",
      "ABC 54605\n",
      "AME 54606\n",
      "AMGN 54611\n",
      "ANTM 54613\n",
      "AON 54614\n",
      "AAPL 54653\n",
      "AMAT 54659\n",
      "APTV 54660\n",
      "ANET 54666\n",
      "AIZ 54667\n",
      "T 54678\n",
      "ATO 54679\n",
      "BKR 54680\n",
      "BAC 54684\n",
      "BK 54686\n",
      "BAX 54687\n",
      "BDX 54689\n",
      "BRK.B 54690\n",
      "BBY 54692\n",
      "BIO 54696\n",
      "BIIB 54700\n",
      "BLK 54703\n",
      "BA 54715\n",
      "BKNG 54717\n",
      "BXP 54718\n",
      "BSX 54721\n",
      "BMY 54729\n",
      "CDNS 54730\n",
      "COF 54731\n",
      "CAH 54732\n",
      "CCL 54735\n",
      "CARR 54742\n",
      "CTLT 54753\n",
      "CAT 54754\n",
      "CBOE 54756\n",
      "CNC 54757\n",
      "CERN 54758\n",
      "SCHW 54759\n",
      "CHTR 54760\n",
      "CVX 54764\n",
      "CMG 54772\n",
      "CB 54773\n",
      "CI 54776\n",
      "CSCO 54789\n",
      "C 54792\n",
      "CTXS 54794\n",
      "CLX 54799\n",
      "KO 54811\n",
      "CTSH 54812\n",
      "CL 54815\n",
      "CMCSA 54820\n",
      "CPRT 54821\n",
      "CTVA 54826\n",
      "COST 54829\n",
      "CCI 54831\n",
      "CSX 54841\n",
      "CMI 54843\n",
      "DHI 54844\n",
      "DHR 54848\n",
      "DRI 54849\n",
      "DVA 54852\n",
      "DE 54853\n",
      "DAL 54857\n",
      "DXCM 54858\n",
      "DFS 54861\n",
      "DISCK 54862\n",
      "DPZ 54863\n",
      "DOW 54866\n",
      "EMN 54867\n",
      "EBAY 54870\n",
      "EW 54874\n",
      "EL 54885\n",
      "EXPE 54888\n",
      "EXR 54889\n",
      "XOM 54893\n",
      "FFIV 54900\n",
      "FB 54928\n",
      "FAST 54929\n",
      "FDX 54930\n",
      "FITB 54932\n",
      "FE 54934\n",
      "FRC 54935\n",
      "FISV 54936\n",
      "FMC 54938\n",
      "F 54954\n",
      "FOXA 54956\n",
      "FOX 54959\n",
      "FCX 54961\n",
      "GPS 54962\n",
      "GRMN 54963\n",
      "GE 54966\n",
      "GIS 54968\n",
      "GM 54992\n",
      "GPC 54994\n",
      "GILD 55003\n",
      "GL 55006\n",
      "GS 55014\n",
      "GWW 55016\n",
      "HBI 55017\n",
      "HCA 55018\n",
      "PEAK 55019\n",
      "HSIC 55021\n",
      "HSY 55022\n",
      "HLT 55025\n",
      "HOLX 55026\n",
      "HD 55037\n",
      "HON 55039\n",
      "HUM 55040\n",
      "HBAN 55042\n",
      "IEX 55043\n",
      "ILMN 55044\n",
      "INCY 55047\n",
      "IR 55048\n",
      "INTC 55059\n",
      "IBM 55066\n",
      "IP 55068\n",
      "INTU 55072\n",
      "ISRG 55073\n",
      "IPGP 55075\n",
      "J 55076\n",
      "JNJ 55089\n",
      "JPM 55098\n",
      "JNPR 55099\n",
      "KSU 55100\n",
      "K 55102\n",
      "KEYS 55105\n",
      "KMB 55108\n",
      "KIM 55109\n",
      "KMI 55110\n",
      "KLAC 55115\n",
      "KHC 55117\n",
      "KR 55120\n",
      "LHX 55122\n",
      "LH 55124\n",
      "LRCX 55127\n",
      "LVS 55132\n",
      "LEG 55133\n",
      "LDOS 55135\n",
      "LLY 55145\n",
      "LYV 55147\n",
      "LMT 55149\n",
      "L 55150\n",
      "LOW 55164\n",
      "MTB 55166\n",
      "MPC 55169\n",
      "MAR 55170\n",
      "MA 55176\n",
      "MCD 55181\n",
      "MCK 55184\n",
      "MDT 55185\n",
      "MRK 55193\n",
      "MET 55194\n",
      "MTD 55195\n",
      "MGM 55198\n",
      "MCHP 55200\n",
      "MU 55202\n",
      "MSFT 55220\n",
      "MHK 55221\n",
      "MS 55229\n",
      "MOS 55230\n",
      "MSI 55231\n",
      "MSCI 55232\n",
      "MYL 55234\n",
      "NFLX 55247\n",
      "NWL 55248\n",
      "NWSA 55251\n",
      "NWS 55254\n",
      "NEE 55255\n",
      "NLSN 55262\n",
      "NKE 55264\n",
      "NI 55266\n",
      "NSC 55269\n",
      "NOC 55273\n",
      "NLOK 55275\n",
      "NRG 55277\n",
      "NUE 55279\n",
      "NVDA 55295\n",
      "OXY 55296\n",
      "ORCL 55299\n",
      "OTIS 55302\n",
      "PCAR 55303\n",
      "PKG 55304\n",
      "PYPL 55324\n",
      "PBCT 55325\n",
      "PEP 55328\n",
      "PRGO 55329\n",
      "PFE 55389\n",
      "PSX 55394\n",
      "PNW 55395\n",
      "PNC 55399\n",
      "POOL 55402\n",
      "PG 55404\n",
      "PRU 55405\n",
      "PHM 55407\n",
      "PWR 55408\n",
      "QCOM 55411\n",
      "DGX 55414\n",
      "RJF 55415\n",
      "RTX 55416\n",
      "O 55417\n",
      "REGN 55420\n",
      "RMD 55422\n",
      "RHI 55424\n",
      "ROST 55430\n",
      "CRM 55432\n",
      "SBAC 55433\n",
      "STX 55434\n",
      "SEE 55436\n",
      "SRE 55437\n",
      "SPG 55439\n",
      "SWKS 55440\n",
      "SNA 55442\n",
      "SO 55443\n",
      "LUV 55450\n",
      "SBUX 55458\n",
      "STE 55460\n",
      "SIVB 55463\n",
      "SYY 55464\n",
      "TROW 55465\n",
      "TPR 55466\n",
      "TGT 55488\n",
      "TER 55490\n",
      "TXN 55492\n",
      "TMO 55493\n",
      "TIF 55495\n",
      "TJX 55497\n",
      "TSCO 55500\n",
      "TT 55502\n",
      "TDG 55511\n",
      "TWTR 55532\n",
      "TSN 55539\n",
      "ULTA 55540\n",
      "UAA 55545\n",
      "UA 55548\n",
      "UNP 55554\n",
      "UAL 55557\n",
      "UNH 55558\n",
      "UPS 55560\n",
      "URI 55561\n",
      "VFC 55562\n",
      "VLO 55564\n",
      "VRSN 55565\n",
      "VZ 55571\n",
      "VRTX 55573\n",
      "V 55574\n",
      "VNO 55575\n",
      "WAB 55576\n",
      "WMT 55615\n",
      "WBA 55620\n",
      "DIS 55643\n",
      "WM 55645\n",
      "WFC 55649\n",
      "WELL 55650\n",
      "WST 55656\n",
      "WHR 55664\n",
      "WMB 55665\n",
      "WYNN 55666\n",
      "XRX 55668\n",
      "XLNX 55670\n",
      "YUM 55673\n",
      "ZBRA 55674\n",
      "ZBH 55675\n",
      "ZTS 55676\n"
     ]
    }
   ],
   "source": [
    "news= dill.load(open('data/news.pkd', 'rb'))\n",
    "for ticker in all_ticker_news.keys():\n",
    "    dates=[]\n",
    "    newsl=[]\n",
    "    possents=[]\n",
    "    negsents=[]  \n",
    "    if all_ticker_news[ticker]:\n",
    "        for date,news_list in all_ticker_news[ticker].items():\n",
    "            if date not in news.loc[ticker].index:\n",
    "                for item in news_list:\n",
    "                    dates.append(date)\n",
    "                    newsl.append(item)\n",
    "                    possents.append(pos_sentiment(item))\n",
    "                    negsents.append(neg_sentiment(item))\n",
    "    if dates:\n",
    "        df=pd.DataFrame([ticker]*len(dates),columns=['Ticker'])\n",
    "        df['Date']=dates\n",
    "        df['NewsText']=newsl\n",
    "        df['PosSentiment']=df['NewsText'].apply(pos_sentiment)\n",
    "        df['NegSentiment']=df['NewsText'].apply(neg_sentiment)\n",
    "        df['SentimentClass']=sgdpipe1.predict(df[['NewsText','PosSentiment','NegSentiment']])\n",
    "        df['SentimentIndex']=df['SentimentClass'].apply(lambda x: 1 if x=='Positive' else -1 if x=='Negative' else 0)\n",
    "        df=df.set_index(['Ticker','Date'])\n",
    "        news=news.append(df[['NewsText','PosSentiment','NegSentiment','SentimentClass','SentimentIndex']])\n",
    "        print(ticker,len(news))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NewsText</th>\n",
       "      <th>PosSentiment</th>\n",
       "      <th>NegSentiment</th>\n",
       "      <th>SentimentClass</th>\n",
       "      <th>SentimentIndex</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-02-02</th>\n",
       "      <td>The GOP Surveillance Memo: What You Need To Know</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-05</th>\n",
       "      <td>The Market In 5 Minutes: Stocks And Cryptos Ma...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-06</th>\n",
       "      <td>2 Pros Break Down The Market Meltdown</td>\n",
       "      <td>1</td>\n",
       "      <td>-2</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-07</th>\n",
       "      <td>The Market In 5 Minutes: Snap Beats, Wynn Resi...</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-02-08</th>\n",
       "      <td>Another Rough Day For The Markets</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>Robinhood Co-Founder Vladimir Tenev Talks Youn...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>This Is How Much Prediction Markets Made On Pr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-19</th>\n",
       "      <td>Investor Optimism Dented Globally On Rising CO...</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>The Week In Cannabis: Stocks Outperform S&amp;P, M...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>Positive</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-20</th>\n",
       "      <td>Global Markets Today: Asia, Europe Rise Cautio...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>Neutral</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1118 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     NewsText PosSentiment  \\\n",
       "Date                                                                         \n",
       "2018-02-02   The GOP Surveillance Memo: What You Need To Know            0   \n",
       "2018-02-05  The Market In 5 Minutes: Stocks And Cryptos Ma...            0   \n",
       "2018-02-06              2 Pros Break Down The Market Meltdown            1   \n",
       "2018-02-07  The Market In 5 Minutes: Snap Beats, Wynn Resi...            0   \n",
       "2018-02-08                  Another Rough Day For The Markets            0   \n",
       "...                                                       ...          ...   \n",
       "2020-11-19  Robinhood Co-Founder Vladimir Tenev Talks Youn...            0   \n",
       "2020-11-19  This Is How Much Prediction Markets Made On Pr...            0   \n",
       "2020-11-19  Investor Optimism Dented Globally On Rising CO...            1   \n",
       "2020-11-20  The Week In Cannabis: Stocks Outperform S&P, M...            1   \n",
       "2020-11-20  Global Markets Today: Asia, Europe Rise Cautio...            0   \n",
       "\n",
       "           NegSentiment SentimentClass  SentimentIndex  \n",
       "Date                                                    \n",
       "2018-02-02            0       Positive               1  \n",
       "2018-02-05            0       Positive               1  \n",
       "2018-02-06           -2       Positive               1  \n",
       "2018-02-07           -1       Positive               1  \n",
       "2018-02-08           -1       Positive               1  \n",
       "...                 ...            ...             ...  \n",
       "2020-11-19            0       Positive               1  \n",
       "2020-11-19            0       Positive               1  \n",
       "2020-11-19           -1       Positive               1  \n",
       "2020-11-20            0       Positive               1  \n",
       "2020-11-20           -2        Neutral               0  \n",
       "\n",
       "[1118 rows x 5 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news=news.sort_index()\n",
    "news.loc['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(news, open('data/news.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Select stocks that have enough news on days before unemployment announcements\n",
    "At least 50% of the time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_UR_Releases = dill.load(open('data/df_UR_Releases.pkd', 'rb'))\n",
    "tickers = dill.load(open('data/tickers.pkd', 'rb'))\n",
    "\n",
    "news= dill.load(open('data/news.pkd', 'rb'))\n",
    "\n",
    "start_date=datetime(2018,3,8) #the day before the first release to consider\n",
    "\n",
    "pre_rel_dates=[x-timedelta(days=1) for x in df_UR_Releases['Release Date'] if x>=start_date]\n",
    "pre_rel_dates=[x-timedelta(days=1) if x==datetime(2019,7,4) else x for x in pre_rel_dates]\n",
    "\n",
    "def validate_ticker(ticker):\n",
    "    invalid_count=0\n",
    "    valid_count=0\n",
    "    try:\n",
    "        df_ticker_news=news.groupby(['Ticker','Date']).agg({'SentimentIndex':'sum'}).loc[ticker]\n",
    "        for date in pre_rel_dates:\n",
    "            if date in df_ticker_news.index:\n",
    "                valid_count+=1\n",
    "            else:\n",
    "                invalid_count+=1\n",
    "        if invalid_count>valid_count:\n",
    "            #print (\"not enough news for \"+ticker)\n",
    "            return False\n",
    "    except KeyError:\n",
    "        #print (\"no news for \"+ticker)\n",
    "        return False\n",
    "    return True\n",
    "\n",
    "valid_tickers=[]\n",
    "for ticker in tickers:\n",
    "    if validate_ticker(ticker):\n",
    "        valid_tickers.append(ticker)\n",
    "dill.dump(valid_tickers, open('data/valid_tickers.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train ARIMA models for selected stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flor/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY 16.06914218954535\n",
      "AMZN 2127.3218644956855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flor/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AAPL 2.7900025127680186\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flor/anaconda3/lib/python3.6/site-packages/statsmodels/base/model.py:568: ConvergenceWarning: Maximum Likelihood optimization failed to converge. Check mle_retvals\n",
      "  \"Check mle_retvals\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FB 23.207296996444736\n",
      "GM 0.5988619306148006\n",
      "MSFT 9.567525400998367\n",
      "TWTR 1.5504917904703395\n"
     ]
    }
   ],
   "source": [
    "d_all_EOD = dill.load(open('data/d_all_EOD.pkd', 'rb'))\n",
    "valid_tickers = dill.load(open('data/valid_tickers.pkd', 'rb'))\n",
    "start_date=datetime(2018,3,8)\n",
    "\n",
    "def train_arima(ticker):\n",
    "     \n",
    "    df=d_all_EOD[ticker][['date','adjClose']]\n",
    "    df=df.set_index('date')\n",
    "\n",
    "    train_data=df.loc[:start_date].values\n",
    "    test_data=df.loc[start_date:].values\n",
    "    train_data=[x for x in train_data]\n",
    "    predictions=[]\n",
    "    for i in range(len(test_data)):\n",
    "        model=ARIMA(train_data,order=(4,1,0))\n",
    "        output=model.fit(disp=0).forecast()\n",
    "        predictions.append(output[0])\n",
    "        train_data.append(test_data[i])\n",
    "    print(ticker, mean_squared_error(test_data, predictions))\n",
    "    return model,[x[0] for x in predictions]\n",
    "\n",
    "arima_models={}\n",
    "for ticker in valid_tickers:\n",
    "    arima_models[ticker]=train_arima(ticker)\n",
    "dill.dump(arima_models, open('data/arima_models.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPY', 'AMZN', 'AAPL', 'FB', 'GM', 'MSFT', 'TWTR']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_tickers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Create machine learning datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/flor/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:17: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "df_UR_Releases = dill.load(open('data/df_UR_Releases.pkd', 'rb'))\n",
    "news = dill.load(open('data/news.pkd', 'rb'))\n",
    "\n",
    "rates=df_UR_Releases[df_UR_Releases['Release Date']>=start_date]['Announced Value'].values\n",
    "changes=df_UR_Releases[df_UR_Releases['Release Date']>=start_date]['Announced Percent Change'].values\n",
    "\n",
    "pre_rel_dates=[x-timedelta(days=1) for x in df_UR_Releases['Release Date'] if x>=start_date]\n",
    "pre_rel_dates=[x-timedelta(days=1) if x==datetime(2019,7,4) else x for x in pre_rel_dates]\n",
    "\n",
    "def create_dataframe(ticker, arima_predictions):\n",
    "    \n",
    "    df=d_all_EOD[ticker][['date','adjClose']]\n",
    "    df=df.set_index('date')\n",
    "    df['nextClose']=df['adjClose'].shift(-1)\n",
    "    \n",
    "    df1=df.loc[start_date:]\n",
    "    df1['predicted']=arima_predictions\n",
    "    \n",
    "    pre_rel_data=[row for row in df1.to_records() if row[0] in pre_rel_dates]\n",
    "\n",
    "    df2=pd.DataFrame()\n",
    "    df2['date']=[x[0] for x in pre_rel_data]\n",
    "    df2['rate']=rates\n",
    "    df2['change']=changes\n",
    "    df2['close']=[x[1] for x in pre_rel_data]\n",
    "    \n",
    "    sentiment=[]\n",
    "    df_news_sentiment=news.groupby(['Ticker','Date']).agg({'SentimentIndex':'sum'}).loc[ticker]\n",
    "    for date in pre_rel_dates:\n",
    "        if date in df_news_sentiment.index:\n",
    "            sentiment.append(df_news_sentiment.loc[date][0])\n",
    "        else:\n",
    "            sentiment.append(0)\n",
    "    df2['sentiment']=sentiment\n",
    "    \n",
    "    df2['predicted']=[x[2] for x in pre_rel_data]\n",
    "    df2['nextClose']=[x[3] for x in pre_rel_data ]\n",
    "    df2['nextChange']=[1 if x[3]-x[1]>0 else -1 for x in pre_rel_data ]\n",
    "    \n",
    "    \n",
    "    return df2.set_index('date')\n",
    "\n",
    "valid_datasets={}\n",
    "for ticker in valid_tickers:\n",
    "    valid_datasets[ticker]=create_dataframe(ticker,arima_models[ticker][1])\n",
    "dill.dump(valid_datasets, open('data/valid_datasets.pkd', 'wb'))    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rate</th>\n",
       "      <th>change</th>\n",
       "      <th>close</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>predicted</th>\n",
       "      <th>nextClose</th>\n",
       "      <th>nextChange</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2018-03-08</th>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>260.141486</td>\n",
       "      <td>1</td>\n",
       "      <td>264.668574</td>\n",
       "      <td>260.147569</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-04-05</th>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>253.120741</td>\n",
       "      <td>1</td>\n",
       "      <td>247.479743</td>\n",
       "      <td>250.824045</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-03</th>\n",
       "      <td>3.9</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>250.243070</td>\n",
       "      <td>2</td>\n",
       "      <td>253.482833</td>\n",
       "      <td>250.881168</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-05-31</th>\n",
       "      <td>3.8</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>258.170960</td>\n",
       "      <td>2</td>\n",
       "      <td>260.705597</td>\n",
       "      <td>259.878082</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-07-05</th>\n",
       "      <td>4.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>261.408370</td>\n",
       "      <td>5</td>\n",
       "      <td>263.619396</td>\n",
       "      <td>259.369652</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-08-02</th>\n",
       "      <td>3.9</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>270.290761</td>\n",
       "      <td>2</td>\n",
       "      <td>271.448917</td>\n",
       "      <td>268.891432</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-09-06</th>\n",
       "      <td>3.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>275.813540</td>\n",
       "      <td>1</td>\n",
       "      <td>275.277534</td>\n",
       "      <td>276.803669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-10-04</th>\n",
       "      <td>3.7</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>278.293574</td>\n",
       "      <td>0</td>\n",
       "      <td>276.735960</td>\n",
       "      <td>280.589327</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-11-01</th>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>262.977043</td>\n",
       "      <td>1</td>\n",
       "      <td>261.419430</td>\n",
       "      <td>260.152856</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2018-12-06</th>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>259.448376</td>\n",
       "      <td>2</td>\n",
       "      <td>253.419836</td>\n",
       "      <td>260.108057</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-03</th>\n",
       "      <td>3.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>236.205643</td>\n",
       "      <td>2</td>\n",
       "      <td>244.117531</td>\n",
       "      <td>241.941924</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-01-31</th>\n",
       "      <td>4.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>261.082631</td>\n",
       "      <td>0</td>\n",
       "      <td>261.208370</td>\n",
       "      <td>258.700326</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-03-07</th>\n",
       "      <td>3.8</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>265.996126</td>\n",
       "      <td>1</td>\n",
       "      <td>265.464153</td>\n",
       "      <td>268.304256</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-04-04</th>\n",
       "      <td>3.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>278.984806</td>\n",
       "      <td>1</td>\n",
       "      <td>280.335140</td>\n",
       "      <td>278.283469</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-05-02</th>\n",
       "      <td>3.6</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>282.870659</td>\n",
       "      <td>1</td>\n",
       "      <td>285.639329</td>\n",
       "      <td>283.579392</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-06-06</th>\n",
       "      <td>3.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>276.672724</td>\n",
       "      <td>0</td>\n",
       "      <td>279.441394</td>\n",
       "      <td>274.848231</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-07-03</th>\n",
       "      <td>3.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>291.686662</td>\n",
       "      <td>0</td>\n",
       "      <td>291.354756</td>\n",
       "      <td>289.377757</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-08-01</th>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>287.820935</td>\n",
       "      <td>0</td>\n",
       "      <td>285.653785</td>\n",
       "      <td>290.461797</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-09-05</th>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.729992</td>\n",
       "      <td>1</td>\n",
       "      <td>290.954516</td>\n",
       "      <td>286.901060</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-03</th>\n",
       "      <td>3.5</td>\n",
       "      <td>-5.41</td>\n",
       "      <td>284.821247</td>\n",
       "      <td>0</td>\n",
       "      <td>288.675484</td>\n",
       "      <td>282.888250</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-10-31</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.86</td>\n",
       "      <td>297.482367</td>\n",
       "      <td>1</td>\n",
       "      <td>300.238195</td>\n",
       "      <td>298.321161</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-12-05</th>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>306.004840</td>\n",
       "      <td>0</td>\n",
       "      <td>308.799897</td>\n",
       "      <td>305.560183</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-01-09</th>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>321.920954</td>\n",
       "      <td>0</td>\n",
       "      <td>320.994563</td>\n",
       "      <td>319.895043</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-02-06</th>\n",
       "      <td>3.6</td>\n",
       "      <td>2.86</td>\n",
       "      <td>329.144835</td>\n",
       "      <td>3</td>\n",
       "      <td>327.390605</td>\n",
       "      <td>328.027643</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-03-05</th>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>298.081163</td>\n",
       "      <td>2</td>\n",
       "      <td>293.153550</td>\n",
       "      <td>308.609669</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-04-02</th>\n",
       "      <td>4.4</td>\n",
       "      <td>25.71</td>\n",
       "      <td>249.708793</td>\n",
       "      <td>2</td>\n",
       "      <td>246.099454</td>\n",
       "      <td>246.559878</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-05-07</th>\n",
       "      <td>14.7</td>\n",
       "      <td>234.09</td>\n",
       "      <td>285.256823</td>\n",
       "      <td>1</td>\n",
       "      <td>289.976728</td>\n",
       "      <td>283.157857</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-06-04</th>\n",
       "      <td>13.3</td>\n",
       "      <td>-9.52</td>\n",
       "      <td>308.737362</td>\n",
       "      <td>0</td>\n",
       "      <td>316.650145</td>\n",
       "      <td>309.214072</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-07-01</th>\n",
       "      <td>11.1</td>\n",
       "      <td>-16.54</td>\n",
       "      <td>309.267382</td>\n",
       "      <td>0</td>\n",
       "      <td>310.970483</td>\n",
       "      <td>306.544535</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-08-06</th>\n",
       "      <td>10.2</td>\n",
       "      <td>-8.11</td>\n",
       "      <td>332.981333</td>\n",
       "      <td>0</td>\n",
       "      <td>333.220365</td>\n",
       "      <td>330.536654</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-09-03</th>\n",
       "      <td>8.4</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>343.996718</td>\n",
       "      <td>0</td>\n",
       "      <td>341.188094</td>\n",
       "      <td>355.696855</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-10-01</th>\n",
       "      <td>7.9</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>337.040000</td>\n",
       "      <td>1</td>\n",
       "      <td>333.840000</td>\n",
       "      <td>334.111763</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2020-11-05</th>\n",
       "      <td>6.9</td>\n",
       "      <td>-12.66</td>\n",
       "      <td>350.240000</td>\n",
       "      <td>2</td>\n",
       "      <td>350.160000</td>\n",
       "      <td>343.588728</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            rate  change       close  sentiment   predicted   nextClose  \\\n",
       "date                                                                      \n",
       "2018-03-08   4.1    0.00  260.141486          1  264.668574  260.147569   \n",
       "2018-04-05   4.1    0.00  253.120741          1  247.479743  250.824045   \n",
       "2018-05-03   3.9   -4.88  250.243070          2  253.482833  250.881168   \n",
       "2018-05-31   3.8   -2.56  258.170960          2  260.705597  259.878082   \n",
       "2018-07-05   4.0    5.26  261.408370          5  263.619396  259.369652   \n",
       "2018-08-02   3.9   -2.50  270.290761          2  271.448917  268.891432   \n",
       "2018-09-06   3.9    0.00  275.813540          1  275.277534  276.803669   \n",
       "2018-10-04   3.7   -5.13  278.293574          0  276.735960  280.589327   \n",
       "2018-11-01   3.7    0.00  262.977043          1  261.419430  260.152856   \n",
       "2018-12-06   3.7    0.00  259.448376          2  253.419836  260.108057   \n",
       "2019-01-03   3.9    5.41  236.205643          2  244.117531  241.941924   \n",
       "2019-01-31   4.0    2.56  261.082631          0  261.208370  258.700326   \n",
       "2019-03-07   3.8   -5.00  265.996126          1  265.464153  268.304256   \n",
       "2019-04-04   3.8    0.00  278.984806          1  280.335140  278.283469   \n",
       "2019-05-02   3.6   -5.26  282.870659          1  285.639329  283.579392   \n",
       "2019-06-06   3.6    0.00  276.672724          0  279.441394  274.848231   \n",
       "2019-07-03   3.7    2.78  291.686662          0  291.354756  289.377757   \n",
       "2019-08-01   3.7    0.00  287.820935          0  285.653785  290.461797   \n",
       "2019-09-05   3.7    0.00  290.729992          1  290.954516  286.901060   \n",
       "2019-10-03   3.5   -5.41  284.821247          0  288.675484  282.888250   \n",
       "2019-10-31   3.6    2.86  297.482367          1  300.238195  298.321161   \n",
       "2019-12-05   3.5   -2.78  306.004840          0  308.799897  305.560183   \n",
       "2020-01-09   3.5    0.00  321.920954          0  320.994563  319.895043   \n",
       "2020-02-06   3.6    2.86  329.144835          3  327.390605  328.027643   \n",
       "2020-03-05   3.5   -2.78  298.081163          2  293.153550  308.609669   \n",
       "2020-04-02   4.4   25.71  249.708793          2  246.099454  246.559878   \n",
       "2020-05-07  14.7  234.09  285.256823          1  289.976728  283.157857   \n",
       "2020-06-04  13.3   -9.52  308.737362          0  316.650145  309.214072   \n",
       "2020-07-01  11.1  -16.54  309.267382          0  310.970483  306.544535   \n",
       "2020-08-06  10.2   -8.11  332.981333          0  333.220365  330.536654   \n",
       "2020-09-03   8.4  -17.65  343.996718          0  341.188094  355.696855   \n",
       "2020-10-01   7.9   -5.95  337.040000          1  333.840000  334.111763   \n",
       "2020-11-05   6.9  -12.66  350.240000          2  350.160000  343.588728   \n",
       "\n",
       "            nextChange  \n",
       "date                    \n",
       "2018-03-08           1  \n",
       "2018-04-05          -1  \n",
       "2018-05-03           1  \n",
       "2018-05-31           1  \n",
       "2018-07-05          -1  \n",
       "2018-08-02          -1  \n",
       "2018-09-06           1  \n",
       "2018-10-04           1  \n",
       "2018-11-01          -1  \n",
       "2018-12-06           1  \n",
       "2019-01-03           1  \n",
       "2019-01-31          -1  \n",
       "2019-03-07           1  \n",
       "2019-04-04          -1  \n",
       "2019-05-02           1  \n",
       "2019-06-06          -1  \n",
       "2019-07-03          -1  \n",
       "2019-08-01           1  \n",
       "2019-09-05          -1  \n",
       "2019-10-03          -1  \n",
       "2019-10-31           1  \n",
       "2019-12-05          -1  \n",
       "2020-01-09          -1  \n",
       "2020-02-06          -1  \n",
       "2020-03-05           1  \n",
       "2020-04-02          -1  \n",
       "2020-05-07          -1  \n",
       "2020-06-04           1  \n",
       "2020-07-01          -1  \n",
       "2020-08-06          -1  \n",
       "2020-09-03           1  \n",
       "2020-10-01          -1  \n",
       "2020-11-05          -1  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_datasets['SPY']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Train and predict\n",
    "\n",
    "We use forward chaining cross validation and the last six months values are predicted values. After cross-validating, we select the best regressor for each stock."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 309.1152432067128, True), (Timestamp('2020-07-01 00:00:00'), 305.5923611425665, True), (Timestamp('2020-08-06 00:00:00'), 328.932228484557, True), (Timestamp('2020-09-03 00:00:00'), 341.6200463005004, False), (Timestamp('2020-10-01 00:00:00'), 334.35937647502436, True), (Timestamp('2020-11-05 00:00:00'), 350.0829148849252, True)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 309.6383871617386, True), (Timestamp('2020-07-01 00:00:00'), 306.74360734764184, True), (Timestamp('2020-08-06 00:00:00'), 325.11482921803315, True), (Timestamp('2020-09-03 00:00:00'), 343.29905044033666, False), (Timestamp('2020-10-01 00:00:00'), 331.7798456013591, True), (Timestamp('2020-11-05 00:00:00'), 342.99440980925783, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 312.203620489414, True), (Timestamp('2020-07-01 00:00:00'), 307.90699873419214, True), (Timestamp('2020-08-06 00:00:00'), 318.8435893711752, True), (Timestamp('2020-09-03 00:00:00'), 328.6740534106205, False), (Timestamp('2020-10-01 00:00:00'), 333.6535916058184, True), (Timestamp('2020-11-05 00:00:00'), 338.39232868747257, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 309.72199379593496, True), (Timestamp('2020-07-01 00:00:00'), 305.8689339587667, True), (Timestamp('2020-08-06 00:00:00'), 329.0311970845697, True), (Timestamp('2020-09-03 00:00:00'), 341.62168835605365, False), (Timestamp('2020-10-01 00:00:00'), 334.2890222801842, True), (Timestamp('2020-11-05 00:00:00'), 350.0439490625481, True)]})\n",
      "best based on mape: Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
      "      random_state=None, solver='auto', tol=0.001) best based on accuracy: LR 0.8333333333333334\n",
      "AMZN\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 2481.5021360289247, True), (Timestamp('2020-07-01 00:00:00'), 2808.965696030161, True), (Timestamp('2020-08-06 00:00:00'), 3137.3622871301513, True), (Timestamp('2020-09-03 00:00:00'), 3391.3239457459094, True), (Timestamp('2020-10-01 00:00:00'), 3189.358335991412, True), (Timestamp('2020-11-05 00:00:00'), 3351.2029953453666, False)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 2394.4498438755504, False), (Timestamp('2020-07-01 00:00:00'), 2573.247181538796, True), (Timestamp('2020-08-06 00:00:00'), 2964.7762796695206, True), (Timestamp('2020-09-03 00:00:00'), 3358.584653231122, False), (Timestamp('2020-10-01 00:00:00'), 3080.022413008726, True), (Timestamp('2020-11-05 00:00:00'), 3146.184167568501, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 2154.897883224924, False), (Timestamp('2020-07-01 00:00:00'), 2306.5393935503207, True), (Timestamp('2020-08-06 00:00:00'), 2564.885817001165, True), (Timestamp('2020-09-03 00:00:00'), 2863.5722254718107, False), (Timestamp('2020-10-01 00:00:00'), 3023.6199576387176, True), (Timestamp('2020-11-05 00:00:00'), 3173.0670446096474, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 2481.827779463003, True), (Timestamp('2020-07-01 00:00:00'), 2809.963761578819, True), (Timestamp('2020-08-06 00:00:00'), 3136.8546231422333, True), (Timestamp('2020-09-03 00:00:00'), 3386.720351677776, True), (Timestamp('2020-10-01 00:00:00'), 3187.0548471827506, True), (Timestamp('2020-11-05 00:00:00'), 3349.351126351973, False)]})\n",
      "best based on mape: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) best based on accuracy: LR 0.8333333333333334\n",
      "AAPL\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 81.12647116064338, True), (Timestamp('2020-07-01 00:00:00'), 89.9034064494167, False), (Timestamp('2020-08-06 00:00:00'), 109.86422673248427, True), (Timestamp('2020-09-03 00:00:00'), 124.34234488322195, True), (Timestamp('2020-10-01 00:00:00'), 115.31531897142474, True), (Timestamp('2020-11-05 00:00:00'), 118.73828167133348, True)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 78.5255691418017, False), (Timestamp('2020-07-01 00:00:00'), 88.10335945073554, False), (Timestamp('2020-08-06 00:00:00'), 102.8417398873725, True), (Timestamp('2020-09-03 00:00:00'), 121.05774004440094, True), (Timestamp('2020-10-01 00:00:00'), 110.4128921481484, True), (Timestamp('2020-11-05 00:00:00'), 114.49893659838152, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 75.2807510909449, False), (Timestamp('2020-07-01 00:00:00'), 80.4520903715339, False), (Timestamp('2020-08-06 00:00:00'), 87.32775914899784, True), (Timestamp('2020-09-03 00:00:00'), 98.68101444656072, False), (Timestamp('2020-10-01 00:00:00'), 105.91535168377304, True), (Timestamp('2020-11-05 00:00:00'), 112.54589155616058, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 81.15695436563894, True), (Timestamp('2020-07-01 00:00:00'), 89.87463346672261, False), (Timestamp('2020-08-06 00:00:00'), 109.80121325885045, True), (Timestamp('2020-09-03 00:00:00'), 124.2453627562744, True), (Timestamp('2020-10-01 00:00:00'), 115.28561662042284, True), (Timestamp('2020-11-05 00:00:00'), 118.79982014894992, True)]})\n",
      "best based on mape: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) best based on accuracy: LR 0.8333333333333334\n",
      "FB\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 229.74796141550448, True), (Timestamp('2020-07-01 00:00:00'), 229.59869964256004, True), (Timestamp('2020-08-06 00:00:00'), 257.7867850491631, True), (Timestamp('2020-09-03 00:00:00'), 281.5373147153599, False), (Timestamp('2020-10-01 00:00:00'), 258.4775752779584, True), (Timestamp('2020-11-05 00:00:00'), 290.6453137896333, True)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 225.12628075311076, False), (Timestamp('2020-07-01 00:00:00'), 225.39532515114558, True), (Timestamp('2020-08-06 00:00:00'), 238.71023146538457, True), (Timestamp('2020-09-03 00:00:00'), 282.51121827130066, False), (Timestamp('2020-10-01 00:00:00'), 255.183367843798, True), (Timestamp('2020-11-05 00:00:00'), 280.83062544260713, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 209.45017999548514, False), (Timestamp('2020-07-01 00:00:00'), 216.2835413543381, True), (Timestamp('2020-08-06 00:00:00'), 226.3363112554493, True), (Timestamp('2020-09-03 00:00:00'), 244.7711496426362, False), (Timestamp('2020-10-01 00:00:00'), 254.1519055346253, True), (Timestamp('2020-11-05 00:00:00'), 265.150854466492, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 229.4161455562955, True), (Timestamp('2020-07-01 00:00:00'), 229.52773870513167, True), (Timestamp('2020-08-06 00:00:00'), 257.75628261612485, True), (Timestamp('2020-09-03 00:00:00'), 281.360720576639, False), (Timestamp('2020-10-01 00:00:00'), 258.4406230952167, True), (Timestamp('2020-11-05 00:00:00'), 290.57696627844837, True)]})\n",
      "best based on mape: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) best based on accuracy: LR 0.8333333333333334\n",
      "GM\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 29.081754206313125, True), (Timestamp('2020-07-01 00:00:00'), 25.206281604523248, True), (Timestamp('2020-08-06 00:00:00'), 26.5407483100385, True), (Timestamp('2020-09-03 00:00:00'), 29.896418116658328, True), (Timestamp('2020-10-01 00:00:00'), 30.61197886554544, False), (Timestamp('2020-11-05 00:00:00'), 36.39520393956718, True)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 29.16003231657796, False), (Timestamp('2020-07-01 00:00:00'), 26.18898041590317, True), (Timestamp('2020-08-06 00:00:00'), 26.420476156572544, True), (Timestamp('2020-09-03 00:00:00'), 29.936226624976097, True), (Timestamp('2020-10-01 00:00:00'), 29.66520440421086, True), (Timestamp('2020-11-05 00:00:00'), 35.337883232025895, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 32.964874876179536, False), (Timestamp('2020-07-01 00:00:00'), 30.274134634030112, True), (Timestamp('2020-08-06 00:00:00'), 28.76543573970787, False), (Timestamp('2020-09-03 00:00:00'), 28.730721513163985, False), (Timestamp('2020-10-01 00:00:00'), 30.45876571180163, False), (Timestamp('2020-11-05 00:00:00'), 34.49558563466508, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 29.337251107933813, False), (Timestamp('2020-07-01 00:00:00'), 25.399735480679716, True), (Timestamp('2020-08-06 00:00:00'), 26.662501722317128, False), (Timestamp('2020-09-03 00:00:00'), 29.96240108462313, True), (Timestamp('2020-10-01 00:00:00'), 30.597106365605736, False), (Timestamp('2020-11-05 00:00:00'), 36.352689883214126, True)]})\n",
      "best based on mape: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) best based on accuracy: LR 0.8333333333333334\n",
      "MSFT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 184.7659133759073, True), (Timestamp('2020-07-01 00:00:00'), 202.67234429786328, True), (Timestamp('2020-08-06 00:00:00'), 210.2937310444717, True), (Timestamp('2020-09-03 00:00:00'), 225.09661278522947, True), (Timestamp('2020-10-01 00:00:00'), 204.17005404205887, True), (Timestamp('2020-11-05 00:00:00'), 226.07338432106843, False)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 180.9908252617555, False), (Timestamp('2020-07-01 00:00:00'), 193.9894614957231, True), (Timestamp('2020-08-06 00:00:00'), 204.86914429371856, True), (Timestamp('2020-09-03 00:00:00'), 219.11294871923633, True), (Timestamp('2020-10-01 00:00:00'), 209.2427032666044, True), (Timestamp('2020-11-05 00:00:00'), 213.47226602542818, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 168.29444355575146, False), (Timestamp('2020-07-01 00:00:00'), 178.75564827859307, True), (Timestamp('2020-08-06 00:00:00'), 189.6680634921981, True), (Timestamp('2020-09-03 00:00:00'), 201.52040246561234, False), (Timestamp('2020-10-01 00:00:00'), 207.7594868113145, True), (Timestamp('2020-11-05 00:00:00'), 213.54622666263694, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 184.9115476468624, True), (Timestamp('2020-07-01 00:00:00'), 202.81232396217985, True), (Timestamp('2020-08-06 00:00:00'), 210.35915211095713, True), (Timestamp('2020-09-03 00:00:00'), 220.89272010936978, True), (Timestamp('2020-10-01 00:00:00'), 206.01563513121292, True), (Timestamp('2020-11-05 00:00:00'), 225.30606159065715, False)]})\n",
      "best based on mape: LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False) best based on accuracy: LR 0.8333333333333334\n",
      "TWTR\n",
      "defaultdict(<class 'list'>, {'LR': [(Timestamp('2020-06-04 00:00:00'), 34.898325870414126, True), (Timestamp('2020-07-01 00:00:00'), 30.722650584903118, True), (Timestamp('2020-08-06 00:00:00'), 36.22535325923251, True), (Timestamp('2020-09-03 00:00:00'), 39.53837375040824, False), (Timestamp('2020-10-01 00:00:00'), 44.78376858033798, True), (Timestamp('2020-11-05 00:00:00'), 42.16371146726986, True)], 'RF': [(Timestamp('2020-06-04 00:00:00'), 34.69014527470403, True), (Timestamp('2020-07-01 00:00:00'), 30.07629466574615, True), (Timestamp('2020-08-06 00:00:00'), 36.00277421603873, True), (Timestamp('2020-09-03 00:00:00'), 42.200549553642595, True), (Timestamp('2020-10-01 00:00:00'), 43.86989443666288, True), (Timestamp('2020-11-05 00:00:00'), 43.06687185357244, True)], 'KR': [(Timestamp('2020-06-04 00:00:00'), 34.048246689079676, True), (Timestamp('2020-07-01 00:00:00'), 31.005958660982163, False), (Timestamp('2020-08-06 00:00:00'), 36.98754491193162, True), (Timestamp('2020-09-03 00:00:00'), 36.966412067523876, False), (Timestamp('2020-10-01 00:00:00'), 41.81529964926034, True), (Timestamp('2020-11-05 00:00:00'), 41.51642938658043, True)], 'RR': [(Timestamp('2020-06-04 00:00:00'), 34.86256094187304, True), (Timestamp('2020-07-01 00:00:00'), 30.787126746620075, True), (Timestamp('2020-08-06 00:00:00'), 36.21122254516774, True), (Timestamp('2020-09-03 00:00:00'), 39.46799545062405, False), (Timestamp('2020-10-01 00:00:00'), 44.67416763512526, True), (Timestamp('2020-11-05 00:00:00'), 42.10839999770957, True)]})\n",
      "best based on mape: RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
      "                      max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "                      max_samples=None, min_impurity_decrease=0.0,\n",
      "                      min_impurity_split=None, min_samples_leaf=1,\n",
      "                      min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "                      n_estimators=100, n_jobs=None, oob_score=False,\n",
      "                      random_state=None, verbose=0, warm_start=False) best based on accuracy: RF 1.0\n"
     ]
    }
   ],
   "source": [
    "valid_tickers = dill.load(open('data/valid_tickers.pkd', 'rb'))\n",
    "valid_datasets = dill.load(open('data/valid_datasets.pkd', 'rb'))\n",
    "def mape(ytrue,ypred):\n",
    "    return abs(ytrue-ypred)/ytrue*100\n",
    "\n",
    "def train_model(ticker,df):\n",
    "    \n",
    "    print(ticker)\n",
    "    cut_date=datetime(2020,6,4)\n",
    "    val_dates=df.loc[cut_date:].index\n",
    "    \n",
    "    regressors={'LR':LinearRegression(),'RF':RandomForestRegressor(),\n",
    "                'KR':KNeighborsRegressor(n_neighbors=5),'RR':Ridge(alpha=10)}\n",
    "    \n",
    "    classifiers={'KNN':KNeighborsClassifier(n_neighbors=5),\n",
    "            'SGD':SGDClassifier(max_iter=1000),\n",
    "            'RFC':RandomForestClassifier(n_estimators=50)}\n",
    "    \n",
    "    best_regressors=[]\n",
    "    best_classifiers=[]\n",
    "    reg_predictions=defaultdict(list)\n",
    "    clf_predictions=defaultdict(list)\n",
    "    for date in val_dates:\n",
    "        X_train=df.loc[:date][['rate','change','predicted','sentiment']]\n",
    "        y_train_reg=df.loc[:date]['nextClose']\n",
    "        y_train_clf=df.loc[:date]['nextChange']\n",
    "        \n",
    "        min_error=100000\n",
    "        for name,regressor in regressors.items():\n",
    "            reg = regressor\n",
    "            trained_reg=reg.fit(X_train,y_train_reg)\n",
    "            prediction=trained_reg.predict(np.array(df.loc[date][['rate','change','predicted','sentiment']]).reshape(1,-1))\n",
    "            reg_predictions[name].append((date,prediction[0]\n",
    "                                ,np.sign(prediction[0]-df.loc[date]['close'])==y_train_clf.loc[date]))\n",
    "            score=reg.score(X_train,y_train_reg)\n",
    "            print(name,score,df.loc[date]['close'],prediction[0],df.loc[date]['nextClose'],df.loc[date]['nextChange'])\n",
    "            if np.sign(df.loc[date]['nextChange'])==np.sign(prediction[0]-df.loc[date]['close']):\n",
    "                error=mape(df.loc[date]['nextClose'],prediction[0])\n",
    "                if error<min_error:\n",
    "                    min_error=error\n",
    "                    best_regressor=name\n",
    "        print(best_regressor,'error=',min_error,'%')   \n",
    "        best_regressors.append(regressors[best_regressor])\n",
    "        \n",
    "        clf_scores=defaultdict(list)\n",
    "        for name,classifier in classifiers.items():\n",
    "            clf=classifier\n",
    "            trained_clf=clf.fit(X_train,y_train_clf)\n",
    "            prediction=trained_clf.predict(np.array(df.loc[date][['rate','change','predicted','sentiment']]).reshape(1,-1))\n",
    "            clf_predictions[name].append(prediction[0])\n",
    "            score=clf.score(X_train,y_train_clf)\n",
    "            print(name,score,df.loc[date]['close'],prediction[0],df.loc[date]['nextClose'],df.loc[date]['nextChange'])\n",
    "            if np.sign(df.loc[date]['nextChange'])==np.sign(prediction[0]):\n",
    "                clf_scores[name].append(1)\n",
    "            else:\n",
    "                clf_scores[name].append(0)\n",
    "                \n",
    "    clf_scores=dict([(item[0],sum(item[1]) )for item in clf_scores.items()])   \n",
    "    print(clf_scores)\n",
    "    best_clf=max(clf_scores,key=clf_scores.get)#classifiers[max(clf_scores,key=clf_scores.get)]\n",
    "    \n",
    "    print('best classifier: ' ,best_clf,clf_scores[best_clf])\n",
    "    \n",
    "    best_reg_count=Counter(best_regressors)\n",
    "    best_reg=max(best_reg_count,key=best_reg_count.get)\n",
    "    \n",
    "    best_acc=0\n",
    "    print(reg_predictions)\n",
    "    for reg in reg_predictions.keys():\n",
    "        accuracy=sum([x[2] for x in reg_predictions[reg]])/len(reg_predictions[reg]) \n",
    "        if accuracy>best_acc:\n",
    "            best_acc=accuracy\n",
    "            best_acc_reg=reg\n",
    "    print('best based on mape:',best_reg,'best based on accuracy:',best_acc_reg,best_acc)\n",
    "    best_reg.fit(X_train,y_train_reg)\n",
    "    mape_error=np.mean(mape(y_train_reg[cut_date:],[x[1] for x in reg_predictions[best_regressor]]))\n",
    "    return best_reg,mape_error,reg_predictions[best_regressor]\n",
    "    \n",
    "predictions={}\n",
    "for ticker in valid_tickers:\n",
    "    predictions[ticker]=train_model(ticker,valid_datasets[ticker])\n",
    "dill.dump(predictions, open('data/predictions/valid_predictions.pkd', 'wb'))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'SPY': (RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False),\n",
       "  0.9030456479152223,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 309.29851024866286),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 307.44861710358947),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 326.1911672209862),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 345.0863741604417),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 331.9784855110338),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 344.1379858897966)]),\n",
       " 'AMZN': (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       "  4.9970829037859765,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 2356.7780860844814),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 2601.571815568447),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 2922.17235835708),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 3274.0237764355243),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 3063.35627480863),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 3248.524559059846)]),\n",
       " 'AAPL': (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       "  4.669833152726164,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 78.95147165121442),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 86.96916475325197),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 99.57791632576594),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 120.04554528387003),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 113.54930027755877),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 115.1194375547833)]),\n",
       " 'FB': (Ridge(alpha=10, copy_X=True, fit_intercept=True, max_iter=None, normalize=False,\n",
       "        random_state=None, solver='auto', tol=0.001),\n",
       "  2.5282012791909807,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 229.4161455562955),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 229.52773870513167),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 257.75628261612485),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 281.360720576639),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 258.4406230952167),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 290.57696627844837)]),\n",
       " 'GM': (RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False),\n",
       "  1.4709756502866471,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 28.571159155066415),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 25.995721279512654),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 26.262864436617807),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 29.928377952385116),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 29.751985155248768),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 35.32839011236048)]),\n",
       " 'MSFT': (LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False),\n",
       "  7.409396889248225,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 168.29444355575146),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 178.75564827859307),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 189.6680634921981),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 201.52040246561234),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 207.7594868113145),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 213.54622666263694)]),\n",
       " 'TWTR': (RandomForestRegressor(bootstrap=True, ccp_alpha=0.0, criterion='mse',\n",
       "                        max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                        max_samples=None, min_impurity_decrease=0.0,\n",
       "                        min_impurity_split=None, min_samples_leaf=1,\n",
       "                        min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "                        n_estimators=100, n_jobs=None, oob_score=False,\n",
       "                        random_state=None, verbose=0, warm_start=False),\n",
       "  1.2340811123033053,\n",
       "  [(Timestamp('2020-06-04 00:00:00'), 34.7887295888348),\n",
       "   (Timestamp('2020-07-01 00:00:00'), 29.92331081486371),\n",
       "   (Timestamp('2020-08-06 00:00:00'), 36.12487493569861),\n",
       "   (Timestamp('2020-09-03 00:00:00'), 42.196809622038025),\n",
       "   (Timestamp('2020-10-01 00:00:00'), 43.96796633258098),\n",
       "   (Timestamp('2020-11-05 00:00:00'), 43.259167717023495)])}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "d_train_dfs={}\n",
    "for ticker in tickers:\n",
    "    tdf=create_train_df(ticker)\n",
    "    if type(tdf)==pd.DataFrame:\n",
    "        d_train_dfs[ticker]=create_train_df(ticker)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>date</th>\n",
       "      <th>rate</th>\n",
       "      <th>change</th>\n",
       "      <th>close</th>\n",
       "      <th>predicted</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-02-02</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>261.422737</td>\n",
       "      <td>267.508507</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-03-09</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>264.668574</td>\n",
       "      <td>260.147569</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-04-06</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>247.479743</td>\n",
       "      <td>253.216681</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-05-04</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-4.88</td>\n",
       "      <td>253.482833</td>\n",
       "      <td>250.462649</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-06-01</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-2.56</td>\n",
       "      <td>260.705597</td>\n",
       "      <td>258.109977</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018-07-06</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.26</td>\n",
       "      <td>263.619396</td>\n",
       "      <td>261.456980</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018-08-03</td>\n",
       "      <td>3.9</td>\n",
       "      <td>-2.50</td>\n",
       "      <td>271.448917</td>\n",
       "      <td>270.385252</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018-09-07</td>\n",
       "      <td>3.9</td>\n",
       "      <td>0.00</td>\n",
       "      <td>275.277534</td>\n",
       "      <td>275.954526</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018-10-05</td>\n",
       "      <td>3.7</td>\n",
       "      <td>-5.13</td>\n",
       "      <td>276.735960</td>\n",
       "      <td>278.432623</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018-11-02</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>261.419430</td>\n",
       "      <td>262.971745</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018-12-07</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>253.419836</td>\n",
       "      <td>259.774695</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2019-01-04</td>\n",
       "      <td>3.9</td>\n",
       "      <td>5.41</td>\n",
       "      <td>244.117531</td>\n",
       "      <td>236.390947</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2019-02-01</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.56</td>\n",
       "      <td>261.208370</td>\n",
       "      <td>261.090580</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2019-03-08</td>\n",
       "      <td>3.8</td>\n",
       "      <td>-5.00</td>\n",
       "      <td>265.464153</td>\n",
       "      <td>266.186579</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2019-04-05</td>\n",
       "      <td>3.8</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280.335140</td>\n",
       "      <td>278.938657</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2019-05-03</td>\n",
       "      <td>3.6</td>\n",
       "      <td>-5.26</td>\n",
       "      <td>285.639329</td>\n",
       "      <td>283.001634</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2019-06-07</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.00</td>\n",
       "      <td>279.441394</td>\n",
       "      <td>276.719027</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2019-07-05</td>\n",
       "      <td>3.7</td>\n",
       "      <td>2.78</td>\n",
       "      <td>291.354756</td>\n",
       "      <td>291.702411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2019-08-02</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>285.653785</td>\n",
       "      <td>288.028775</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2019-09-06</td>\n",
       "      <td>3.7</td>\n",
       "      <td>0.00</td>\n",
       "      <td>290.954516</td>\n",
       "      <td>290.621734</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2019-10-04</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-5.41</td>\n",
       "      <td>288.675484</td>\n",
       "      <td>284.851210</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2019-11-01</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.86</td>\n",
       "      <td>300.238195</td>\n",
       "      <td>297.525942</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2019-12-06</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>308.799897</td>\n",
       "      <td>306.087899</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2020-01-10</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>320.994563</td>\n",
       "      <td>321.870564</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2020-02-07</td>\n",
       "      <td>3.6</td>\n",
       "      <td>2.86</td>\n",
       "      <td>327.390605</td>\n",
       "      <td>329.067338</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2020-03-06</td>\n",
       "      <td>3.5</td>\n",
       "      <td>-2.78</td>\n",
       "      <td>293.153550</td>\n",
       "      <td>298.027574</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2020-04-03</td>\n",
       "      <td>4.4</td>\n",
       "      <td>25.71</td>\n",
       "      <td>246.099454</td>\n",
       "      <td>246.782683</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2020-05-08</td>\n",
       "      <td>14.7</td>\n",
       "      <td>234.09</td>\n",
       "      <td>289.976728</td>\n",
       "      <td>284.626723</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2020-06-05</td>\n",
       "      <td>13.3</td>\n",
       "      <td>-9.52</td>\n",
       "      <td>316.650145</td>\n",
       "      <td>309.471824</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2020-07-02</td>\n",
       "      <td>11.1</td>\n",
       "      <td>-16.54</td>\n",
       "      <td>310.970483</td>\n",
       "      <td>310.199289</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2020-08-07</td>\n",
       "      <td>10.2</td>\n",
       "      <td>-8.11</td>\n",
       "      <td>333.220365</td>\n",
       "      <td>332.807006</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2020-09-04</td>\n",
       "      <td>8.4</td>\n",
       "      <td>-17.65</td>\n",
       "      <td>341.188094</td>\n",
       "      <td>346.940613</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2020-10-02</td>\n",
       "      <td>7.9</td>\n",
       "      <td>-5.95</td>\n",
       "      <td>333.840000</td>\n",
       "      <td>336.612717</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2020-11-06</td>\n",
       "      <td>6.9</td>\n",
       "      <td>-12.66</td>\n",
       "      <td>350.160000</td>\n",
       "      <td>350.126320</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         date  rate  change       close   predicted  sentiment\n",
       "0  2018-02-02   4.1    0.00  261.422737  267.508507          1\n",
       "1  2018-03-09   4.1    0.00  264.668574  260.147569          0\n",
       "2  2018-04-06   4.1    0.00  247.479743  253.216681          6\n",
       "3  2018-05-04   3.9   -4.88  253.482833  250.462649          4\n",
       "4  2018-06-01   3.8   -2.56  260.705597  258.109977          1\n",
       "5  2018-07-06   4.0    5.26  263.619396  261.456980          1\n",
       "6  2018-08-03   3.9   -2.50  271.448917  270.385252          1\n",
       "7  2018-09-07   3.9    0.00  275.277534  275.954526          1\n",
       "8  2018-10-05   3.7   -5.13  276.735960  278.432623          2\n",
       "9  2018-11-02   3.7    0.00  261.419430  262.971745          3\n",
       "10 2018-12-07   3.7    0.00  253.419836  259.774695          5\n",
       "11 2019-01-04   3.9    5.41  244.117531  236.390947          4\n",
       "12 2019-02-01   4.0    2.56  261.208370  261.090580          2\n",
       "13 2019-03-08   3.8   -5.00  265.464153  266.186579          2\n",
       "14 2019-04-05   3.8    0.00  280.335140  278.938657          2\n",
       "15 2019-05-03   3.6   -5.26  285.639329  283.001634          0\n",
       "16 2019-06-07   3.6    0.00  279.441394  276.719027          1\n",
       "17 2019-07-05   3.7    2.78  291.354756  291.702411          0\n",
       "18 2019-08-02   3.7    0.00  285.653785  288.028775          0\n",
       "19 2019-09-06   3.7    0.00  290.954516  290.621734          0\n",
       "20 2019-10-04   3.5   -5.41  288.675484  284.851210          1\n",
       "21 2019-11-01   3.6    2.86  300.238195  297.525942          4\n",
       "22 2019-12-06   3.5   -2.78  308.799897  306.087899          1\n",
       "23 2020-01-10   3.5    0.00  320.994563  321.870564          3\n",
       "24 2020-02-07   3.6    2.86  327.390605  329.067338          2\n",
       "25 2020-03-06   3.5   -2.78  293.153550  298.027574          0\n",
       "26 2020-04-03   4.4   25.71  246.099454  246.782683          0\n",
       "27 2020-05-08  14.7  234.09  289.976728  284.626723          1\n",
       "28 2020-06-05  13.3   -9.52  316.650145  309.471824          1\n",
       "29 2020-07-02  11.1  -16.54  310.970483  310.199289          0\n",
       "30 2020-08-07  10.2   -8.11  333.220365  332.807006          0\n",
       "31 2020-09-04   8.4  -17.65  341.188094  346.940613          3\n",
       "32 2020-10-02   7.9   -5.95  333.840000  336.612717          4\n",
       "33 2020-11-06   6.9  -12.66  350.160000  350.126320          2"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d_train_dfs['SPY']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(d_train_dfs, open('data/d_train_dfs.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SPY 0.995418572351244\n",
      "GOOGL 0.9893671030271621\n",
      "GOOG 0.9824830291594422\n",
      "AMZN 0.9957285887579254\n",
      "AAPL 0.9971915867831391\n",
      "BA 0.9951737619883345\n",
      "DAL 0.9950362121375359\n",
      "XOM 0.9936167618267246\n",
      "FB 0.993936899308937\n",
      "FDX 0.9927569182464169\n",
      "F 0.9880338702695479\n",
      "GM 0.9857433476365604\n",
      "MRK 0.9966533282113345\n",
      "MSFT 0.9980369610447868\n",
      "NFLX 0.9944497893987981\n",
      "UPS 0.996392740132636\n",
      "WMT 0.9970021392388302\n",
      "DIS 0.9974164579254955\n"
     ]
    }
   ],
   "source": [
    "d_trained_models={}\n",
    "d_predictions={}\n",
    "for ticker in d_train_dfs.keys():\n",
    "    X=d_train_dfs[ticker][['rate','change','predicted','sentiment']]\n",
    "    y=d_train_dfs[ticker]['close']\n",
    "    regressors={'LR':LinearRegression(),'RF':RandomForestRegressor(),\n",
    "                'KR':KNeighborsRegressor(n_neighbors=5),'RR':Ridge(alpha=10),\n",
    "               'SGDR':SGDRegressor()}\n",
    "    max_score=0\n",
    "    for name,regressor in regressors.items():\n",
    "        reg = regressor\n",
    "        trained_model=reg.fit(X,y)\n",
    "        score=reg.score(X,y)\n",
    "        if score>max_score:\n",
    "            max_score=score\n",
    "            best_model=trained_model\n",
    "    print(ticker,max_score)\n",
    "    d_trained_models[ticker]=best_model\n",
    "    predictions=pd.DataFrame(best_model.predict(X)\n",
    "                                       ,d_train_dfs[ticker]['date'],columns=['prediction'])\n",
    "    d_predictions[ticker]=predictions\n",
    "    dill.dump(predictions, open('data/predictions/'+ticker+'.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "dill.dump(d_predictions, open('data/d_predictions.pkd', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
